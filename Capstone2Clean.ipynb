{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone2Clean",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNeQ2Z6f5Srf9krYd4Oi9ZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rosez/Springboard/blob/master/Capstone2Clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq26_5st8vwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enrAzW-7s1YC",
        "colab_type": "text"
      },
      "source": [
        "# Capstone2 : Apparel Images\n",
        "\n",
        "\n",
        "This project evaluates models to classify the Kaggle Apparel image dataset. Due to resource contraints on the initial implementation on local laptop, it uses 10 classes or the original 24 classes in the dataset.\n",
        "\n",
        "The project uses a Convolutional Neural Network (CNN).\n",
        "\n",
        "It allows the user to compare various models and configurations.\n",
        "\n",
        "It is currently setup to run in a Google CoLab notebook.\n",
        "\n",
        "We consider multiple models, of varying archetectures (ie., convolution/pool/dense layers and nodes). The models are defined in the module x10MakeModel section.  You specify a 'suffix' to indicate which model to use.\n",
        "\n",
        "Run the project in the main.py section.  The first few sections are setup; the RunMe section allows for running subsets of models and parameters. It uses multiple lists, and will run all combinations of the list entries.\n",
        "\n",
        "\n",
        "\n",
        "**LISTS:**\n",
        "\n",
        "**suffixes**: \tmodel suffixes -- predefined models in the X10MakeModel section\n",
        "\n",
        "**optnames**: \tlist of (encoded) optimizers...they will be decoded in the 'xOptimizer' function.\n",
        "\n",
        "**learning_rates**: learning rates (NOTE: since the learning rate varies by optimizer, will have to do a different call for each optimzer ...it might make more sense to convert this to a dictionary).\n",
        "\n",
        "\n",
        "**pixels**: \timage size (square) in  pixels\n",
        "\n",
        "\n",
        "\n",
        "**SAVED INFORMATION:**\n",
        "\n",
        "For each model, it saves the following:\n",
        "\n",
        "* the trained model parameters\n",
        "* the model.fit() history\n",
        "* plots for loss and accuracy progression during model trainung epochs, for the training and validation data\n",
        "\n",
        "\n",
        " \n",
        "This project uses the Kaggle Apparel dataset\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toRRBYhe5IHC",
        "colab_type": "text"
      },
      "source": [
        "# Import tf to find out version\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSarfeWVVGrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbyCdt455hJW",
        "colab_type": "code",
        "outputId": "81067f65-1d1b-4b2c-9b7d-4e45e5bd7b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX9jxMP2Vwjm",
        "colab_type": "code",
        "outputId": "6d2409d1-43a9-4b63-927f-928f2befe486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "#tf.test.gpu_device_name()\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  2 14:25:48 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    31W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJOu5v61hm0A",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqs9OPua5h-l",
        "colab_type": "text"
      },
      "source": [
        "# Connect to Google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpESIZO1VrW5",
        "colab_type": "code",
        "outputId": "d7445977-b289-4c8f-85e1-980f582b8c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfLsFW9Qehgt",
        "colab_type": "code",
        "outputId": "569048f9-6072-4699-ec50-809abf71b081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "!ls \"/content/gdrive/My Drive/Capstone2/data/\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apparelSmallTest  apparelSmallTrain  apparelSmallValidate  capstone2.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbw2iJMo-7Lf",
        "colab_type": "text"
      },
      "source": [
        "# Moving on ...done with CoLab stuf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YenQ_jSjQXs",
        "colab_type": "text"
      },
      "source": [
        "## Import modules\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQBsl1_OexB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        " \n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioZ8CKgS1sKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRZDnaqwbfhD",
        "colab_type": "text"
      },
      "source": [
        "# Function Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt1eyPxHjRW_",
        "colab_type": "text"
      },
      "source": [
        "## setPixels()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLxFdPmnS3ca",
        "colab_type": "text"
      },
      "source": [
        "variables used  for image size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho7jWS4kbi5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setPixels(img_rows, img_cols, depth=3):\n",
        "    # input image dimensions\n",
        "    img_rows, img_cols = 150, 150\n",
        "    input_shape = (img_rows, img_cols, depth)\n",
        "\n",
        "    target_size = input_shape[:2]\n",
        "    return (input_shape, target_size)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxtTG96NLxia",
        "colab_type": "text"
      },
      "source": [
        "##xOptimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afq_eQpQLqv6",
        "colab_type": "text"
      },
      "source": [
        "Decode optimizer name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acOzt8yNmdn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def getOptimizer(optName, learning_rate, epochs):\n",
        "    if optname == 'Adam':\n",
        "        xoptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    if optname == 'amsgrad':\n",
        "        xoptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, amsgrad=True)\n",
        "        \n",
        "    if optname == 'Sgd':\n",
        "        momentum = 0.8\n",
        "        #epochs = 250\n",
        "        decay_rate = learning_rate / epochs\n",
        "        xoptimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate)\n",
        "    if optname =='sgdStep':\n",
        "        momentum = 0.8\n",
        "        xoptimizer = tf.keras.optimizers.SGD(learning_rate=0.0, momentum=momentum)\n",
        "        \n",
        "    return xoptimizer\n",
        "\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_0llShGbyx-",
        "colab_type": "text"
      },
      "source": [
        "## Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L0pPTEy058y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataGenerators(target_size):\n",
        "    #!!import tensorflow as tf\n",
        "    import keras_preprocessing\n",
        "    from keras_preprocessing import image\n",
        "    from keras_preprocessing.image import ImageDataGenerator\n",
        "    \n",
        "    TRAINING_DIR = trainingdir\n",
        "    training_datagen = ImageDataGenerator(\n",
        "          rescale = 1./255,\n",
        "    \t  rotation_range=40,\n",
        "          width_shift_range=0.2,\n",
        "          height_shift_range=0.2,\n",
        "          shear_range=0.2,\n",
        "          zoom_range=0.2,\n",
        "          horizontal_flip=True,\n",
        "          fill_mode='nearest')\n",
        "    \n",
        "    \n",
        "    VALIDATION_DIR = validdir\n",
        "    validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "    \n",
        "    train_generator = training_datagen.flow_from_directory(\n",
        "    \tTRAINING_DIR,\n",
        "    \ttarget_size=target_size,\n",
        "        color_mode='rgb',\n",
        "    \tclass_mode='categorical'\n",
        "    )\n",
        "    \n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "    \tVALIDATION_DIR,\n",
        "    \ttarget_size=target_size,\n",
        "        color_mode='rgb',\n",
        "    \tclass_mode='categorical'\n",
        "    )\n",
        "\n",
        "    \n",
        "    return train_generator, validation_generator\n",
        "    \n",
        "\n",
        "\n",
        "def testDataGenerator(target_size):\n",
        "    #!!import tensorflow as tf\n",
        "    import keras_preprocessing\n",
        "    from keras_preprocessing import image\n",
        "    from keras_preprocessing.image import ImageDataGenerator\n",
        "    \n",
        " \n",
        "    TEST_DIR = testdir\n",
        "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "    \n",
        "    \n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "    \tTEST_DIR,\n",
        "    \ttarget_size=target_size,\n",
        "        color_mode='rgb',\n",
        "    \tclass_mode='categorical'\n",
        "    )\n",
        "    \n",
        "    return test_generator\n",
        "\n",
        "\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1scb-zLWji2L",
        "colab_type": "text"
      },
      "source": [
        "## Save Results\n",
        "* pickle the history file\n",
        "* plot and Save model history\n",
        "* save the evaluation output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNgly19aityg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def pickleHist(history, filename):\n",
        "    import pickle\n",
        " \n",
        "    pfilename = filename + '.pkl'\n",
        "    with open(pfilename, 'wb') as file_pi:\n",
        "            pickle.dump(history.history, file_pi)\n",
        "\n",
        "\n",
        "\n",
        "def pickleEval(eval_output, filename):\n",
        "    import pickle\n",
        " \n",
        "    pfilename = filename + '.pkl'\n",
        "    with open(pfilename, 'wb') as file_pi:\n",
        "            pickle.dump(eval_output, file_pi)           \n",
        "        \n",
        "def plotModelHistory(history, suffix):\n",
        "# Plot training & validation accuracy values\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model{0} accuracy'.format(suffix))\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot training & validation loss values\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model{0} loss'.format(suffix))\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plotSaveModelHistory(history, saveInfo, history_path):\n",
        "# Plot training & validation accuracy values\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model{0} accuracy'.format(saveInfo))\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "    \n",
        "    savefile = history_path + 'Accuracy' + saveInfo + '.pdf'\n",
        "    plt.savefig(savefile)\n",
        "    plt.show()\n",
        " \n",
        "    \n",
        "    # Plot training & validation loss values\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model{0} loss'.format(saveInfo))\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    \n",
        "    savefile = history_path + 'Loss' + saveInfo + '.pdf'\n",
        "    plt.savefig(savefile)\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FPVmf9Umru9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOGvDpZmit_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBxVdNN_kCSS",
        "colab_type": "text"
      },
      "source": [
        "## x10MakeModel.py\n",
        "Make model based on suffix parameter\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf2rXWwOj3Ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Apr 17 12:29:25 2020\n",
        "\n",
        "@author: rozoe\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def make_model(suffix, num_classes, input_shape):\n",
        "\n",
        "#    num_classes, input_shape, learning_rate, epochs = getGlobalParms()\n",
        "    if suffix==1:\n",
        "        print('model1')\n",
        "    \n",
        "        model = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "        #    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        return model\n",
        "\n",
        " \n",
        "\n",
        "    ################### model 2: add another conv/pool layer ################\n",
        "    # del model2\n",
        "\n",
        "    elif (suffix==2):\n",
        "        print('model2')\n",
        " \n",
        "        model2c = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "        #    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        return model2c\n",
        "\n",
        "\n",
        "################### model 3: the original overfitted model ################\n",
        "    elif (suffix==3): \n",
        "        print('model3')\n",
        "        \n",
        "\n",
        "         \n",
        "        model3 = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        return model3\n",
        " \n",
        "\n",
        "\n",
        "################### model 4: complex model inspired by asifbala (from Ankur) ################\n",
        "    elif suffix==4:\n",
        " \n",
        "        model4 = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        return model4\n",
        " \n",
        "    elif suffix==5:\n",
        " \n",
        "################### model 5: pare down m4...too much memory ################\n",
        "# two conv layers before pooling\n",
        "        model5 = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "        #    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "     \n",
        "        return model5\n",
        "        \n",
        "    elif suffix==6:\n",
        "################### model 6: pare down m5, since it crashes the pc ################\n",
        "# two conv layers before pooling\n",
        "\n",
        " \n",
        "        model6 = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "        #    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        return model6\n",
        "     \n",
        "    elif suffix==7:\n",
        "################### model 7: M4 + 2blocks  ################\n",
        "# redo first model, but no pooling after first step \n",
        "# ...exceeds memory during make_model()\n",
        "        model7 = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fifth convolution\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The sizth convolution\n",
        "            #tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "            #tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "            #tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        return model7\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "# =============================================================================\n",
        "#     elif suffix==10:\n",
        "# \n",
        "#     ################### model 10: change the syntax to the viz format #############\n",
        "#     # redo first model, but no pooling after first step\n",
        "#         \n",
        "#         from keras.models import Sequential\n",
        "#         from keras.layers import Conv2D\n",
        "#         from keras.layers import MaxPooling2D\n",
        "#         from keras.layers import Flatten\n",
        "#         from keras.layers import Dense\n",
        "#         from keras.layers import Dropout\n",
        "#         \n",
        "#         classifier10 = Sequential()\n",
        "#         #\n",
        "#          \n",
        "#         # Step 1 - Convolution\n",
        "#         \n",
        "#         classifier10.add(Conv2D(32, (3, 3), padding='same', input_shape = input_shape, activation = 'relu'))\n",
        "#         classifier10.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "#         classifier10.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#         classifier10.add(Dropout(0.5)) # antes era 0.25\n",
        "#         # Adding a second convolutional layer\n",
        "#         classifier10.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
        "#         classifier10.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "#         classifier10.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#         classifier10.add(Dropout(0.5)) # antes era 0.25\n",
        "#         # Adding a third convolutional layer\n",
        "#         ## classifier10.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
        "#         ## classifier10.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "#         ## classifier10.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#         ## classifier10.add(Dropout(0.5)) # antes era 0.25\n",
        "#         # Step 3 - Flattening\n",
        "#         classifier10.add(Flatten())\n",
        "#         # Step 4 - Full connection\n",
        "#         classifier10.add(Dense(units = 512, activation = 'relu'))\n",
        "#         classifier10.add(Dropout(0.5)) \n",
        "#         classifier10.add(Dense(units = num_classes, activation = 'softmax'))\n",
        "#         \n",
        "#         classifier10.summary()\n",
        "#         \n",
        "#         classifier10.compile(optimizer = 'adam',\n",
        "#                            loss = 'categorical_crossentropy', \n",
        "#                            metrics = ['accuracy'])\n",
        "#         \n",
        "#         histEx10Epoch1d10 = classifier10.fit_generator(train_generator,\n",
        "#                                            steps_per_epoch = 100,\n",
        "#                                            epochs = 10,\n",
        "#         #                                  callbacks=[checkpointer],\n",
        "#                                            validation_data = validation_generator,\n",
        "#                                            validation_steps = 50)\n",
        "#         return classifier10\n",
        "# '''    \n",
        "# \n",
        "# \n",
        "# =============================================================================\n",
        " \n",
        "    elif suffix==8:\n",
        "        print('model 8')\n",
        "    ################### model 8: add additional block to model 7 ################\n",
        "    # two conv layers before pooling\n",
        "    #del model8\n",
        "     \n",
        "        model8 = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fifth convolution\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The sizth convolution\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        return model8\n",
        "\n",
        " \n",
        "\n",
        " \n",
        "    elif suffix==9:\n",
        "        ################### model 9: model 6 * 2 num_channels ################\n",
        "        # two conv layers before pooling\n",
        "        \n",
        "        #del model8\n",
        "        model9 = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "        #    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        return model9\n",
        "        \n",
        "        ## model 9: waaay overfit...acc: .11 / .0786\n",
        "    \n",
        "    \n",
        "    elif suffix==11:\n",
        "        print('model11')\n",
        "    \n",
        "        model = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "        #    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "    \n",
        "   \n",
        " \n",
        "    elif suffix==12:\n",
        "        ################### model 12: model 10 in keras################\n",
        "        # two conv layers before pooling\n",
        "        \n",
        " \n",
        "        model12 = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "        #    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        return model12\n",
        "        \n",
        "        ## model 9: waaay overfit...acc: .11 / .0786\n",
        "    \n",
        "    \n",
        " \n",
        "################### model 13: model 2 + 4*dense ################\n",
        " \n",
        "    elif (suffix==13):\n",
        "        print('model13')\n",
        " \n",
        "        model13 = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "        #    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(512, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        return model13\n",
        "\n",
        "        \n",
        "    elif suffix==16:\n",
        "        print('model' , suffix)\n",
        "################### model 6: pare down m5, since it crashes the pc ################\n",
        "# two conv layers before pooling\n",
        "\n",
        "\n",
        " \n",
        "        model16 = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "        #    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        \n",
        "        return model16\n",
        "\n",
        "    elif suffix==101:\n",
        "        # model 1 w/no dropout\n",
        "        print('model101')\n",
        "    \n",
        "        model = tf.keras.models.Sequential([\n",
        "            # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "            tf.keras.layers.MaxPooling2D(2, 2),\n",
        "            # The second convolution\n",
        "        #    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The third convolution\n",
        "        #    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        #    tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # The fourth convolution\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "            tf.keras.layers.MaxPooling2D(2,2),\n",
        "            # Flatten the results to feed into a DNN\n",
        "            tf.keras.layers.Flatten(),\n",
        "            #tf.keras.layers.Dropout(0.5),\n",
        "            # 512 neuron hidden layer\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "        print('did not find suffix')\n",
        "\n",
        "    \n",
        "################################ END MODEL DEFINITION #####################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_05CmFIj3GQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CdLfWxVknuP",
        "colab_type": "text"
      },
      "source": [
        "## x20ProcessModel.py\n",
        "\n",
        "compile and fit model \n",
        "\n",
        "==> return model and history object\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM_gOtyLj3Pt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def processModel(model, suffix, num_epochs, \n",
        "                 xoptimizer, \n",
        "                 train_generator, validation_generator,\n",
        "                 batch_size,\n",
        "                 callbacks=None):\n",
        "    \n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer=xoptimizer, metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    \n",
        "    # calculate step sizes    \n",
        "    #batch_size = 32\n",
        "    steps_per_epoch = int(train_generator.samples / batch_size)\n",
        "    validation_steps = int(validation_generator.samples / batch_size)\n",
        "    test_steps = int(test_generator.samples / batch_size)\n",
        "    \n",
        "    \n",
        "    #es = getEarlyStopping()\n",
        "    ## notation epock1d20 ...epochs 1 dotdotdot 20 ==> 1 thru 20\n",
        "    history  = model.fit(train_generator, epochs=num_epochs, \n",
        "                         validation_data = validation_generator,\n",
        "                         steps_per_epoch=steps_per_epoch,\n",
        "                         validation_steps=validation_steps,\n",
        "                         batch_size=batch_size,\n",
        "                         verbose = 1, callbacks=callbacks)\n",
        "    # plot History\n",
        "    #plotModelHistory(history, suffix)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHRuoNyr8_sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeQAS0bxj-wQ",
        "colab_type": "text"
      },
      "source": [
        "##formatLR()\n",
        "Format the learning rate as a string for use in the saved information label names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2DHk2sw4aGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "\n",
        "\n",
        "def formatLR(lr):\n",
        "    if lr == .001:\n",
        "        return 'LR3'\n",
        "    elif lr == .0001:\n",
        "        return 'LR4'\n",
        "    elif lr == 1e-05:\n",
        "        return 'LR5'\n",
        "    elif lr == 1e-06:\n",
        "        return 'LR6'\n",
        "    elif lr == 1e-07:\n",
        "        return 'LR7'\n",
        "    elif lr == 1e-08:\n",
        "        return 'LR8'\n",
        "    elif lr == .1:\n",
        "        return 'LR1'\n",
        "    elif lr == 0.01:\n",
        "        return 'LR2'\n",
        "    elif lr == 0.0005:\n",
        "        return 'LR5e4'        \n",
        "        \n",
        "    else:\n",
        "        return  'LR' + str(lr)\n",
        "\n",
        "\n",
        "#formatLR(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgTHJlHtk8Jo",
        "colab_type": "text"
      },
      "source": [
        "# main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LoDCWTNb-_R",
        "colab_type": "text"
      },
      "source": [
        "## Directory Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk3afcDRfmhS",
        "colab_type": "code",
        "outputId": "632610a5-17f8-426e-c24e-c1341bc09111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "path = \"/content/gdrive/My Drive/Capstone2/data/\"\n",
        "srcdir = path + 'apparel-images-dataset\\\\'\n",
        "\n",
        "trainingdir = path + 'apparelSmallTrain'\n",
        "testdir = path + 'apparelSmallTest'\n",
        "validdir = path + 'apparelSmallValidate'\n",
        "print(trainingdir)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Capstone2/data/apparelSmallTrain\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dkG9qeubMh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def getHistoryPath():\n",
        "    #history_path = 'C:\\\\Users\\\\rozoe\\\\jy\\\\ch10ML\\\\tensorflow\\\\capstone2\\\\history\\\\'\n",
        "    history_path = \"/content/gdrive/My Drive/Capstone2/history/\"\n",
        "    return history_path  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Krft1_cG4h",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fg6Mm6Rf8X5",
        "colab_type": "code",
        "outputId": "27614de2-9f2c-4b6a-bc9b-05885565a3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "\n",
        "# =============================================================================\n",
        "# inLine Parameters\n",
        "# =============================================================================\n",
        "\n",
        "num_classes = 10\n",
        "num_epochs = 250\n",
        "epochs = num_epochs\n",
        "\n",
        "#batch_size for model.fit\n",
        "batch_size = 32  \n",
        "\n",
        "print(num_classes,  num_epochs, batch_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 250 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfjvrHnhcN71",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhaav8NGmim3",
        "colab_type": "code",
        "outputId": "aa7663ee-c036-4d25-db23-17772cf759dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# =============================================================================\n",
        "# Callbacks\n",
        "# =============================================================================\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8,\n",
        "                   restore_best_weights=True)\n",
        "\n",
        "# drop-based learning rate\n",
        "#https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/\n",
        "\n",
        "def step_decay(epoch):\n",
        "\tinitial_lrate = 0.0005\n",
        "\tdrop = 0.5\n",
        "\tepochs_drop = 10.0\n",
        "\t#epochs_drop = 5.0\n",
        "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "\treturn lrate\n",
        "\n",
        "# learning ratee schedule callback\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "#Callbacks for using step decay learning rate scheduler\n",
        "#callbacks = [es, lrate]\n",
        "\n",
        "# Default callback for Early Stopping\n",
        "callbacks = [es]\n",
        "\n",
        "print(callbacks)\n",
        " \n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f59798b5710>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn19g007g3ju",
        "colab_type": "text"
      },
      "source": [
        "##RunMe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZc-jhOKlaV8",
        "colab_type": "code",
        "outputId": "f8586b95-79e4-473f-eac4-5b6d2c95ead4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "history_path = getHistoryPath()\n",
        "print(history_path)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Capstone2/history/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtX02WPUoBNL",
        "colab_type": "text"
      },
      "source": [
        "### Set parms for looping\n",
        "\n",
        "NOTE: we do two sets of parms, since LR is depending on optimizer....ideally this should be a dictionary, but for now we are doing multiple runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox6S9ViRbZHq",
        "colab_type": "code",
        "outputId": "cd1b44ad-b654-4a62-cac0-a8863970796f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# set parms for looping.\n",
        "\n",
        "# all values\n",
        "#optnames = ['Adam', 'amsgrad', 'Sgd', 'sgdStep']\n",
        "suffixes = [1, 3, 6, 7, 8]\n",
        "\n",
        "\n",
        "\n",
        "# RUN 1\n",
        "optnames = ['amsgrad']\n",
        "learning_rates = [.001,0.0001]\n",
        "pixels = [150, 300]\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "# RUN 2 -- we limite the LRs and pixels based on RUN 1 results\n",
        "#optnames = ['Sgd']\n",
        "#learning_rates = [.01, .1]\n",
        "#pixels = [150]\n",
        "\n",
        "# SAMPLE RUN\n",
        "\n",
        "suffixes = [1, 3]\n",
        "optnames = ['amsgrad']\n",
        "learning_rates = [.001]\n",
        "pixels = [150]\n",
        "\n",
        "print(optnames, learning_rates, suffixes, pixels)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['amsgrad'] [0.001] [1, 3] [150]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-RvtZcxMp0h",
        "colab_type": "text"
      },
      "source": [
        "### Verify run list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnt3aRoqjdbM",
        "colab_type": "code",
        "outputId": "36e5e037-7d09-42e4-cbd7-823ffa5e2179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Verify run list before kicking off lengthy loop\n",
        "\n",
        "for optname in optnames:\n",
        "    for learning_rate in learning_rates:\n",
        "        for suffix in suffixes:\n",
        "            for pixel in pixels:\n",
        "                #setPixels(pixel, pixel)\n",
        "                lrFormatted = formatLR(learning_rate)\n",
        "\n",
        "\n",
        "                # Label saved objects with model suffix and image size\n",
        "                saveInfo = 'M' + str(suffix) + 'Pix' + str(pixel) + lrFormatted + optname\n",
        "                print('SaveInfo: ', saveInfo)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SaveInfo:  M1Pix150LR3amsgrad\n",
            "SaveInfo:  M3Pix150LR3amsgrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX_fHDqWMx8u",
        "colab_type": "text"
      },
      "source": [
        "### Loop through models: define, train, evaluate,  save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ccpamp2zfJN",
        "colab_type": "code",
        "outputId": "6592df14-78aa-48e4-b0f5-75841a4c97ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        }
      },
      "source": [
        "# =============================================================================\n",
        "# Run Models\n",
        "# =============================================================================\n",
        "\n",
        " \n",
        "for optname in optnames:\n",
        "    for learning_rate in learning_rates:\n",
        "        for suffix in suffixes:\n",
        "            for pixel in pixels:\n",
        "\n",
        "                input_shape, target_size = setPixels(pixel, pixel)\n",
        "                lrFormatted = formatLR(learning_rate)\n",
        "\n",
        " \n",
        "                # Label saved objects with model suffix and image size\n",
        "                saveInfo = 'M' + str(suffix) + 'Pix' + str(pixel) + lrFormatted + optname\n",
        "                print('SaveInfo: ', saveInfo)\n",
        "\n",
        "                # get parm-specific details\n",
        "\n",
        "                train_generator, validation_generator = dataGenerators(target_size)\n",
        "\n",
        "                test_generator = testDataGenerator(target_size)\n",
        "\n",
        "                xoptimizer = getOptimizer(optname, learning_rate, epochs) \n",
        "\n",
        "\n",
        "\n",
        "                # Define Model; the suffix indicates which model\n",
        "                model = make_model(suffix, num_classes, input_shape)\n",
        "                model.summary()\n",
        "\n",
        "                # Compile and train model\n",
        "                model, history = processModel(model, saveInfo, 250, \n",
        "                                            xoptimizer, \n",
        "                                            train_generator, validation_generator,\n",
        "                                            batch_size,\n",
        "                                            callbacks=callbacks)\n",
        "\n",
        "\n",
        "                print('*** pickling history ***')\n",
        "                pickleHist(history, history_path + 'history' + saveInfo)\n",
        "                #pickleHist(history, history_path + 'historyLR1e4Epochs21d30Model' + str(suffix))\n",
        "\n",
        "\n",
        "                print('*** plotting/saving history figures ***')\n",
        "                # plot History\n",
        "                #plotModelHistory(history, saveInfo)\n",
        "                plotSaveModelHistory(history, saveInfo, history_path)\n",
        "\n",
        "                print('*** evaluating Model ***')\n",
        "                # Model Evaluation\n",
        "                test_steps = int(test_generator.samples / batch_size)\n",
        "                eval_output = model.evaluate(test_generator, steps=test_steps)         \n",
        "                print(eval_output)\n",
        "\n",
        "                # Save Evaluation information\n",
        "                evalfile = history_path + 'eval' + saveInfo\n",
        "                print(evalfile)\n",
        "                #pickleEval(eval_output, history_path + 'eval' + str(suffix))\n",
        "                pickleEval(eval_output, evalfile)\n",
        "\n",
        "                print('*** saving model  ***')\n",
        "                # Save the entire model as a SavedModel.\n",
        "                savedmodeldir = '/content/gdrive/My Drive/Capstone2/saved_model/'\n",
        "\n",
        "                #!mkdir -p savedmodeldir\n",
        "                #!mkdir -p '/content/gdrive/My Drive/Capstone2/saved_model'\n",
        "                modelpath =  savedmodeldir + 'model' + saveInfo\n",
        "                model.save(modelpath)\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SaveInfo:  M1Pix150LR3amsgrad\n",
            "Found 5055 images belonging to 10 classes.\n",
            "Found 1092 images belonging to 10 classes.\n",
            "Found 1095 images belonging to 10 classes.\n",
            "model1\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 82944)             0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 82944)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               10616960  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 10,637,642\n",
            "Trainable params: 10,637,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/250\n",
            " 75/157 [=============>................] - ETA: 10:46 - loss: 1.7388 - accuracy: 0.4050"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-306ce4ae9531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                                             \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-a0e10edb9367>\u001b[0m in \u001b[0;36mprocessModel\u001b[0;34m(model, suffix, num_epochs, xoptimizer, train_generator, validation_generator, batch_size, callbacks)\u001b[0m\n\u001b[1;32m     25\u001b[0m                          \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                          verbose = 1, callbacks=callbacks)\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# plot History\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#plotModelHistory(history, suffix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7ciDYlHmD7O",
        "colab_type": "text"
      },
      "source": [
        "# Compare Model Results\n",
        "\n",
        "Retrieve the information for the processed models, and compare results, using Holdout data accuracy as the metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW_6l1c2N35L",
        "colab_type": "text"
      },
      "source": [
        "## Setup parms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa2ujEUamKhW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e7544420-1c48-454b-d031-c6acf553c0b6"
      },
      "source": [
        "# all options\n",
        "#optnames = ['Adam', 'amsgrad', 'Sgd', 'sgdStep']\n",
        "learning_rates = [0.01, .001, .0001]\n",
        "suffixes = [1, 3, 6, 7, 8]\n",
        "pixels = [150, 300]\n",
        "\n",
        "# use  a subset of options\n",
        "optnames = ['Sgd','amsgrad']\n",
        "\n",
        "print(optnames, learning_rates, suffixes, pixels)\n",
        "\n",
        "history_path = getHistoryPath()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sgd', 'amsgrad'] [0.01, 0.001, 0.0001] [1, 3, 6, 7, 8] [150, 300]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIhyIfLHN9yp",
        "colab_type": "text"
      },
      "source": [
        "### Create data frame to hold results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuNFg9OfbWF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "e7a8cbf8-c186-4ec6-c599-018997f6bec5"
      },
      "source": [
        "# Generate dataframe to hold results...will use for plotting\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_accuracy = pd.DataFrame({'optimizer': [], 'lr': [], 'pixels': []})\n",
        "\n",
        "for optname in optnames:\n",
        "    for learning_rate in learning_rates:\n",
        "        for pixel in pixels:\n",
        "            df_accuracy = df_accuracy.append(pd.Series([optname, learning_rate, pixel ],\n",
        "                                                       index=df_accuracy.columns), \n",
        "                                             ignore_index=True)\n",
        "\n",
        "xrows = len(df_accuracy)\n",
        "xlist = [None] * len(df_accuracy)\n",
        "\n",
        "for suffix in suffixes:\n",
        "    model_name = 'M' + str(suffix)\n",
        "    df_accuracy[model_name] = xlist\n",
        "\n",
        "print(df_accuracy)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   optimizer      lr  pixels    M1    M3    M6    M7    M8\n",
            "0        Sgd  0.0100   150.0  None  None  None  None  None\n",
            "1        Sgd  0.0100   300.0  None  None  None  None  None\n",
            "2        Sgd  0.0010   150.0  None  None  None  None  None\n",
            "3        Sgd  0.0010   300.0  None  None  None  None  None\n",
            "4        Sgd  0.0001   150.0  None  None  None  None  None\n",
            "5        Sgd  0.0001   300.0  None  None  None  None  None\n",
            "6    amsgrad  0.0100   150.0  None  None  None  None  None\n",
            "7    amsgrad  0.0100   300.0  None  None  None  None  None\n",
            "8    amsgrad  0.0010   150.0  None  None  None  None  None\n",
            "9    amsgrad  0.0010   300.0  None  None  None  None  None\n",
            "10   amsgrad  0.0001   150.0  None  None  None  None  None\n",
            "11   amsgrad  0.0001   300.0  None  None  None  None  None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXGVzZlLOCkX",
        "colab_type": "text"
      },
      "source": [
        "### Populate results table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t5MAzv9aqy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df48bc28-b6c9-454f-f4e9-9915b8c8dde1"
      },
      "source": [
        "# populate results table by retrieving evaluation information from pickled files\n",
        "\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# loop through all combinations\n",
        "for optname in optnames:\n",
        "    for learning_rate in learning_rates:\n",
        "        for suffix in suffixes:\n",
        "            for pixel in pixels:\n",
        " \n",
        "                lrFormatted = formatLR(learning_rate)\n",
        "                model_name = 'M' + str(suffix)\n",
        "\n",
        "\n",
        "                # generate Label format for saved objects with model suffix and image size\n",
        "                saveInfo = model_name + 'Pix' + str(pixel) + lrFormatted + optname\n",
        "                print('SaveInfo: ', saveInfo)\n",
        "\n",
        "                # generate format used for Saved Evaluation information\n",
        "\n",
        "                evalfile = history_path + 'eval' + saveInfo + '.pkl'\n",
        "                print('EvalFile:', evalfile)\n",
        " \n",
        "\n",
        "                try:\n",
        "                    with open(evalfile, 'rb') as handle:\n",
        "                        b = pickle.load(handle)\n",
        "                except:\n",
        "                    print('EXCEPTION: {0} does not exist '.format(evalfile))\n",
        "                    break\n",
        "\n",
        "                with open(evalfile, 'rb') as handle:\n",
        "                    eval_info = pickle.load(handle)\n",
        "\n",
        "                print('eval_info: ', eval_info)\n",
        "\n",
        "                # update results table with accuracy for corresponding experiment  \n",
        "                df_accuracy.loc[(df_accuracy['optimizer'] == optname) & \n",
        "                                (df_accuracy['lr'] == learning_rate) & \n",
        "                                (df_accuracy['pixels'] == pixel),\n",
        "                                model_name] = eval_info[1]\n",
        "\n",
        " \n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SaveInfo:  M1Pix150LR2Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM1Pix150LR2Sgd.pkl\n",
            "eval_info:  [0.31547391414642334, 0.8878676295280457]\n",
            "SaveInfo:  M1Pix300LR2Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM1Pix300LR2Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM1Pix300LR2Sgd.pkl does not exist \n",
            "SaveInfo:  M3Pix150LR2Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM3Pix150LR2Sgd.pkl\n",
            "eval_info:  [0.20603372156620026, 0.9227941036224365]\n",
            "SaveInfo:  M3Pix300LR2Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM3Pix300LR2Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM3Pix300LR2Sgd.pkl does not exist \n",
            "SaveInfo:  M6Pix150LR2Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM6Pix150LR2Sgd.pkl\n",
            "eval_info:  [0.3256545662879944, 0.8795955777168274]\n",
            "SaveInfo:  M6Pix300LR2Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM6Pix300LR2Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM6Pix300LR2Sgd.pkl does not exist \n",
            "SaveInfo:  M7Pix150LR2Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM7Pix150LR2Sgd.pkl\n",
            "eval_info:  [0.16160985827445984, 0.9448529481887817]\n",
            "SaveInfo:  M7Pix300LR2Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM7Pix300LR2Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM7Pix300LR2Sgd.pkl does not exist \n",
            "SaveInfo:  M8Pix150LR2Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM8Pix150LR2Sgd.pkl\n",
            "eval_info:  [0.18311801552772522, 0.9420955777168274]\n",
            "SaveInfo:  M8Pix300LR2Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM8Pix300LR2Sgd.pkl\n",
            "eval_info:  [0.18852195143699646, 0.935661792755127]\n",
            "SaveInfo:  M1Pix150LR3Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM1Pix150LR3Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM1Pix150LR3Sgd.pkl does not exist \n",
            "SaveInfo:  M3Pix150LR3Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM3Pix150LR3Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM3Pix150LR3Sgd.pkl does not exist \n",
            "SaveInfo:  M6Pix150LR3Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM6Pix150LR3Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM6Pix150LR3Sgd.pkl does not exist \n",
            "SaveInfo:  M7Pix150LR3Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM7Pix150LR3Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM7Pix150LR3Sgd.pkl does not exist \n",
            "SaveInfo:  M8Pix150LR3Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM8Pix150LR3Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM8Pix150LR3Sgd.pkl does not exist \n",
            "SaveInfo:  M1Pix150LR4Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM1Pix150LR4Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM1Pix150LR4Sgd.pkl does not exist \n",
            "SaveInfo:  M3Pix150LR4Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM3Pix150LR4Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM3Pix150LR4Sgd.pkl does not exist \n",
            "SaveInfo:  M6Pix150LR4Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM6Pix150LR4Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM6Pix150LR4Sgd.pkl does not exist \n",
            "SaveInfo:  M7Pix150LR4Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM7Pix150LR4Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM7Pix150LR4Sgd.pkl does not exist \n",
            "SaveInfo:  M8Pix150LR4Sgd\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM8Pix150LR4Sgd.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM8Pix150LR4Sgd.pkl does not exist \n",
            "SaveInfo:  M1Pix150LR2amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM1Pix150LR2amsgrad.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM1Pix150LR2amsgrad.pkl does not exist \n",
            "SaveInfo:  M3Pix150LR2amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM3Pix150LR2amsgrad.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM3Pix150LR2amsgrad.pkl does not exist \n",
            "SaveInfo:  M6Pix150LR2amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM6Pix150LR2amsgrad.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM6Pix150LR2amsgrad.pkl does not exist \n",
            "SaveInfo:  M7Pix150LR2amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM7Pix150LR2amsgrad.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM7Pix150LR2amsgrad.pkl does not exist \n",
            "SaveInfo:  M8Pix150LR2amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM8Pix150LR2amsgrad.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM8Pix150LR2amsgrad.pkl does not exist \n",
            "SaveInfo:  M1Pix150LR3amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM1Pix150LR3amsgrad.pkl\n",
            "eval_info:  [0.26562657952308655, 0.9181985259056091]\n",
            "SaveInfo:  M1Pix300LR3amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM1Pix300LR3amsgrad.pkl\n",
            "eval_info:  [0.26272550225257874, 0.9090073704719543]\n",
            "SaveInfo:  M3Pix150LR3amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM3Pix150LR3amsgrad.pkl\n",
            "eval_info:  [0.14346623420715332, 0.9540441036224365]\n",
            "SaveInfo:  M3Pix300LR3amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM3Pix300LR3amsgrad.pkl\n",
            "eval_info:  [0.17778673768043518, 0.9402573704719543]\n",
            "SaveInfo:  M6Pix150LR3amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM6Pix150LR3amsgrad.pkl\n",
            "eval_info:  [0.2197801172733307, 0.9273896813392639]\n",
            "SaveInfo:  M6Pix300LR3amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM6Pix300LR3amsgrad.pkl\n",
            "eval_info:  [0.24501530826091766, 0.908088207244873]\n",
            "SaveInfo:  M7Pix150LR3amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM7Pix150LR3amsgrad.pkl\n",
            "eval_info:  [0.17134642601013184, 0.9448529481887817]\n",
            "SaveInfo:  M7Pix300LR3amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM7Pix300LR3amsgrad.pkl\n",
            "eval_info:  [0.17486771941184998, 0.9430146813392639]\n",
            "SaveInfo:  M8Pix150LR3amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM8Pix150LR3amsgrad.pkl\n",
            "eval_info:  [0.15057942271232605, 0.951286792755127]\n",
            "SaveInfo:  M8Pix300LR3amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM8Pix300LR3amsgrad.pkl\n",
            "eval_info:  [0.2355654090642929, 0.9338235259056091]\n",
            "SaveInfo:  M1Pix150LR4amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM1Pix150LR4amsgrad.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM1Pix150LR4amsgrad.pkl does not exist \n",
            "SaveInfo:  M3Pix150LR4amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM3Pix150LR4amsgrad.pkl\n",
            "eval_info:  [0.1965916007757187, 0.9292279481887817]\n",
            "SaveInfo:  M3Pix300LR4amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM3Pix300LR4amsgrad.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM3Pix300LR4amsgrad.pkl does not exist \n",
            "SaveInfo:  M6Pix150LR4amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM6Pix150LR4amsgrad.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM6Pix150LR4amsgrad.pkl does not exist \n",
            "SaveInfo:  M7Pix150LR4amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM7Pix150LR4amsgrad.pkl\n",
            "eval_info:  [0.1555176079273224, 0.9430146813392639]\n",
            "SaveInfo:  M7Pix300LR4amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM7Pix300LR4amsgrad.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM7Pix300LR4amsgrad.pkl does not exist \n",
            "SaveInfo:  M8Pix150LR4amsgrad\n",
            "EvalFile: /content/gdrive/My Drive/Capstone2/history/evalM8Pix150LR4amsgrad.pkl\n",
            "EXCEPTION: /content/gdrive/My Drive/Capstone2/history/evalM8Pix150LR4amsgrad.pkl does not exist \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh3lMjkXOKTX",
        "colab_type": "text"
      },
      "source": [
        "### Print results table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIAc61SdqA44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "53e77b53-c896-4928-b551-b1cd0ea22e72"
      },
      "source": [
        "# print results table to show which combinations we actually ran...\n",
        "print(df_accuracy)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   optimizer      lr  pixels        M1        M3        M6        M7        M8\n",
            "0        Sgd  0.0100   150.0  0.887868  0.922794  0.879596  0.944853  0.942096\n",
            "1        Sgd  0.0100   300.0      None      None      None      None  0.935662\n",
            "2        Sgd  0.0010   150.0      None      None      None      None      None\n",
            "3        Sgd  0.0010   300.0      None      None      None      None      None\n",
            "4        Sgd  0.0001   150.0      None      None      None      None      None\n",
            "5        Sgd  0.0001   300.0      None      None      None      None      None\n",
            "6    amsgrad  0.0100   150.0      None      None      None      None      None\n",
            "7    amsgrad  0.0100   300.0      None      None      None      None      None\n",
            "8    amsgrad  0.0010   150.0  0.918199  0.954044   0.92739  0.944853  0.951287\n",
            "9    amsgrad  0.0010   300.0  0.909007  0.940257  0.908088  0.943015  0.933824\n",
            "10   amsgrad  0.0001   150.0      None  0.929228      None  0.943015      None\n",
            "11   amsgrad  0.0001   300.0      None      None      None      None      None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBBKBeX8ORl2",
        "colab_type": "text"
      },
      "source": [
        "## Make Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Imw02h_OUC_",
        "colab_type": "text"
      },
      "source": [
        "### Plot: Accuracy for Optimizer vs model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1bcabE0Crtq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "outputId": "70d6051b-b2b1-4507-e943-28a4a0cb4fcd"
      },
      "source": [
        "# plot optimizer vs model for pixels = 150 (and best lr/optimizer)\n",
        "\n",
        "df = df_accuracy\n",
        "#df_filtered = pd.DataFrame(df.loc[(df.pixels==150)]  )\n",
        "\n",
        "\n",
        "df_filtered = pd.DataFrame( df.loc[(((df.optimizer=='amsgrad') & (df.lr == .0010)) |\n",
        "                      ((df.optimizer == 'Sgd') & (df.lr == .01))) &\n",
        "                      (df.pixels == 150)\n",
        "                      ]) [['optimizer','M1','M3','M6','M7','M8']]\n",
        "\n",
        "\n",
        "\n",
        "print('df_filtered \\n', df_filtered)\n",
        "\n",
        "\n",
        "melted = pd.melt(df_filtered, id_vars='optimizer', var_name='model',value_name='accuracy')\n",
        "print('melted \\n', melted)\n",
        "\n",
        "import seaborn as sns\n",
        "sns.catplot(x=\"model\", y=\"accuracy\", hue=\"optimizer\", kind=\"bar\", data=melted);\n",
        "\n",
        "plt.title('Holdout Accuracy by Model and Optimizer')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_filtered \n",
            "   optimizer        M1        M3        M6        M7        M8\n",
            "0       Sgd  0.887868  0.922794  0.879596  0.944853  0.942096\n",
            "8   amsgrad  0.918199  0.954044   0.92739  0.944853  0.951287\n",
            "melted \n",
            "   optimizer model  accuracy\n",
            "0       Sgd    M1  0.887868\n",
            "1   amsgrad    M1  0.918199\n",
            "2       Sgd    M3  0.922794\n",
            "3   amsgrad    M3  0.954044\n",
            "4       Sgd    M6  0.879596\n",
            "5   amsgrad    M6   0.92739\n",
            "6       Sgd    M7  0.944853\n",
            "7   amsgrad    M7  0.944853\n",
            "8       Sgd    M8  0.942096\n",
            "9   amsgrad    M8  0.951287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Holdout Accuracy by Model and Optimizer')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmCwUeCyj76t",
        "colab_type": "text"
      },
      "source": [
        "==> Amsgrad is better (or the same) than Sgd for all models in this case. \n",
        "\n",
        "*Therefore, we use Amsgrad results for subsequent analysis*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKM95LkaOdAY",
        "colab_type": "text"
      },
      "source": [
        "### Plot: Accuracy vs Image Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_CsWDFWSG1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "507ce8f9-4988-451b-ddd7-311c5a75ee35"
      },
      "source": [
        "# Plot accuracy vs image size (optimizer = Amsgrad)\n",
        "\n",
        "#rename data frame for more efficient typing\n",
        "df = df_accuracy\n",
        "df_filtered = pd.DataFrame(df.loc[(df.optimizer=='amsgrad') & (df.lr == .0010)])\n",
        "\n",
        "print(df_filtered)\n",
        " \n",
        "# multiple line plot\n",
        "#plt.plot( 'pixels', 'M1', data=df_filtered, marker='o', markerfacecolor='blue', markersize=12, color='skyblue', linewidth=4)\n",
        "plt.plot( 'pixels', 'M1', data=df_filtered, marker='o', markerfacecolor='blue', markersize=None, color='blue', linewidth=2)\n",
        "plt.plot( 'pixels', 'M3', data=df_filtered, marker='o', color='green', linewidth=2)\n",
        "plt.plot( 'pixels', 'M6', data=df_filtered, marker='o', color='black', linewidth=2, linestyle='solid' )\n",
        "plt.plot( 'pixels', 'M7', data=df_filtered, marker='o', color='brown', linewidth=2, linestyle='solid' )\n",
        "plt.plot( 'pixels', 'M8', data=df_filtered, marker='o', color='orange', linewidth=2, linestyle='solid')\n",
        "#plt.plot( 'pixels', 'M8', data=df_filtered, marker='', color='orange', linewidth=2, linestyle='dashed', label=\"toto\")\n",
        "\n",
        "plt.title('Holdout Accuracy vs Image Size ')\n",
        "plt.xlabel('Image Size (pixels)')\n",
        "plt.ylabel('Holdout Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  optimizer     lr  pixels        M1        M3        M6        M7        M8\n",
            "8   amsgrad  0.001   150.0  0.918199  0.954044   0.92739  0.944853  0.951287\n",
            "9   amsgrad  0.001   300.0  0.909007  0.940257  0.908088  0.943015  0.933824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f585c3394a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6H53nYRh_DP",
        "colab_type": "text"
      },
      "source": [
        "==> Accuracy is better for the smaller image size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3ok_sRuOqx-",
        "colab_type": "text"
      },
      "source": [
        "### Plot: Accuracy vs Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ii17DKWvCAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "45232637-c33c-4229-cbb2-6c6db3441bbe"
      },
      "source": [
        "# Plot accuracy vs learning rate (optimizer = Amsgrad)\n",
        "\n",
        "df = df_accuracy\n",
        "df_filtered = pd.DataFrame(df.loc[(df.optimizer=='amsgrad') & (df.pixels==150)])\n",
        "\n",
        "print(df_filtered)\n",
        "xval = 'lr'\n",
        "\n",
        "# multiple line plot\n",
        "plt.plot( xval, 'M1', data=df_filtered, marker='o', markerfacecolor='blue', markersize=None, color='blue', linewidth=2)\n",
        "plt.plot( xval, 'M3', data=df_filtered, marker='o', color='green', linewidth=2)\n",
        "plt.plot( xval, 'M6', data=df_filtered, marker='o', color='black', linewidth=2, linestyle='solid' )\n",
        "plt.plot( xval, 'M7', data=df_filtered, marker='o', color='brown', linewidth=2, linestyle='solid' )\n",
        "plt.plot( xval, 'M8', data=df_filtered, marker='o', color='orange', linewidth=2, linestyle='solid')\n",
        "#plt.plot( xval, 'M8', data=df_filtered, marker='', color='orange', linewidth=2, linestyle='dashed', label=\"toto\")\n",
        "\n",
        "plt.legend(loc='lower center')\n",
        "plt.title('Holdout Accuracy vs LR (opt=Amsgrad)')\n",
        "plt.xlabel = ('Learning Rate')\n",
        "plt.ylabel = ('Holdout Accuracy')\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   optimizer      lr  pixels        M1        M3       M6        M7        M8\n",
            "6    amsgrad  0.0100   150.0      None      None     None      None      None\n",
            "8    amsgrad  0.0010   150.0  0.918199  0.954044  0.92739  0.944853  0.951287\n",
            "10   amsgrad  0.0001   150.0      None  0.929228     None  0.943015      None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jzlfw5kjTX3",
        "colab_type": "text"
      },
      "source": [
        "==>  the lower learning rate of 1e-4 (.0001) is worse than 1e-3 (.001)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeuhZY31vBDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzhHHHPZO8US",
        "colab_type": "text"
      },
      "source": [
        "# Best Model -- Todo\n",
        "\n",
        "* Confusion Matrix\n",
        "* Example of mis-Classified images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEclC1_SPJ1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}